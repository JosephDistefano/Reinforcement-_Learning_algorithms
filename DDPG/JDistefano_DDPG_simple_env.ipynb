{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project DDPG\n",
    "\n",
    "Original code wrote by:\n",
    "Joseph Distefano(jpdistef@buffalo.edu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch\n",
    "# !pip install numpy\n",
    "# !pip install matplotlib\n",
    "# !pip install gym\n",
    "# !pip install random \n",
    "# !pip install time\n",
    "# !pip install box2d-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "from gym import spaces\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import sys\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import deque, namedtuple\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import *\n",
    "# from keras.optimizers import *\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from matplotlib import rc, animation\n",
    "from IPython import display\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self,state_size,action_size):\n",
    "        super(Critic,self).__init__()\n",
    "        self.linear1 = nn.Linear(state_size,64)\n",
    "        self.linear2 = nn.Linear(action_size+400,300)\n",
    "        self.critic = nn.Linear(300,1)\n",
    "        \n",
    "    def forward(self,state,action):\n",
    "        out = self.linear1(state)\n",
    "        out = F.relu(out)\n",
    "        out = self.linear2(torch.cat([out,a],1))\n",
    "        out = F.relu(out)\n",
    "        criticx =self.critic(out)\n",
    "        return criticx\n",
    "        \n",
    "class Actor(nn.Module):\n",
    "    def __init__(self,state_size,action_size):\n",
    "        super(Actor,self).__init__()\n",
    "        self.linear1 = nn.Linear(state_size,400)\n",
    "        self.linear2 = nn.Linear(400,300)\n",
    "        self.actor = nn.Linear(300,action_size)\n",
    "        \n",
    "    def forward(self,state):\n",
    "        out = self.linear1(state)\n",
    "        out = F.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = F.relu(out)\n",
    "        actorx = F.tanh(self.actor(out)) \n",
    "        return actorx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class replay_buffer:\n",
    "    def __init__(self,mem_size,state_size,action_size,mem_cntr):\n",
    "        self.mem_size = mem_size\n",
    "        self.state_memory = np.zeros((self.mem_size, *[state_size]), dtype=np.float32)\n",
    "        self.new_state_memory = np.zeros((self.mem_size, *[state_size]), dtype=np.float32)\n",
    "        self.action_memory = np.zeros(self.mem_size, dtype=np.int64)\n",
    "        self.reward_memory = np.zeros(self.mem_size, dtype=np.float32)\n",
    "        self.terminal_memory = np.zeros(self.mem_size, dtype=np.uint8)\n",
    "        self.mem_cntr = mem_cntr\n",
    "        self.action_size = action_size\n",
    "        \n",
    "    def storeTransition(self, state, action, reward, state_, terminal):\n",
    "        index = self.mem_cntr % self.mem_size\n",
    "        self.state_memory[index] = state\n",
    "        self.new_state_memory[index] = state_\n",
    "        self.action_memory[index] = action\n",
    "        self.reward_memory[index] = reward\n",
    "        self.terminal_memory[index] = done\n",
    "        self.mem_cntr += 1\n",
    "        \n",
    "    def get_sample(self,batch_size):\n",
    "        max_mem = min(self.mem_cntr, self.mem_size)\n",
    "        batch = np.random.choice(max_mem, batch_size, replace=False)\n",
    "\n",
    "        state_batch = self.state_memory[batch]\n",
    "        action_batch = self.action_memory[batch]\n",
    "        reward_batch = self.reward_memory[batch]\n",
    "        new_state_batch = self.new_state_memory[batch]\n",
    "        terminal_batch = self.terminal_memory[batch]\n",
    "        \n",
    "        return state_batch,action_batch ,reward_batch,new_state_batch,terminal_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### imported this function \n",
    "class RandomProcess(object):\n",
    "    def reset_states(self):\n",
    "        pass\n",
    "\n",
    "class AnnealedGaussianProcess(RandomProcess):\n",
    "    def __init__(self, mu, sigma, sigma_min, n_steps_annealing):\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.n_steps = 0\n",
    "\n",
    "        if sigma_min is not None:\n",
    "            self.m = -float(sigma - sigma_min) / float(n_steps_annealing)\n",
    "            self.c = sigma\n",
    "            self.sigma_min = sigma_min\n",
    "        else:\n",
    "            self.m = 0.\n",
    "            self.c = sigma\n",
    "            self.sigma_min = sigma\n",
    "\n",
    "    @property\n",
    "    def current_sigma(self):\n",
    "        sigma = max(self.sigma_min, self.m * float(self.n_steps) + self.c)\n",
    "        return sigma\n",
    "    \n",
    "class OrnsteinUhlenbeckProcess(AnnealedGaussianProcess):\n",
    "    def __init__(self, theta, mu=0., sigma=1., dt=1e-2, x0=None, size=1, sigma_min=None, n_steps_annealing=1000):\n",
    "        super(OrnsteinUhlenbeckProcess, self).__init__(mu=mu, sigma=sigma, sigma_min=sigma_min, n_steps_annealing=n_steps_annealing)\n",
    "        self.theta = theta\n",
    "        self.mu = mu\n",
    "        self.dt = dt\n",
    "        self.x0 = x0\n",
    "        self.size = size\n",
    "        self.reset_states()\n",
    "\n",
    "    def sample(self):\n",
    "        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + self.current_sigma * np.sqrt(self.dt) * np.random.normal(size=self.size)\n",
    "        self.x_prev = x\n",
    "        self.n_steps += 1\n",
    "        return x\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.x_prev = self.x0 if self.x0 is not None else np.zeros(self.size)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPGagent():\n",
    "    def __init__(self,state_size,action_size,lr,max_mem,tau):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.gamma = lr\n",
    "        self.tau = tau\n",
    "        \n",
    "        self.actor = Actor(state_size,action_size) \n",
    "        self.actor_target = Actor(state_size,action_size)\n",
    "        self.critic = Critic(state_size,action_size)\n",
    "        self.critic_target = Critic(state_size,action_size)\n",
    "        \n",
    "        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(), lr=lr)\n",
    "        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=lr)\n",
    "        \n",
    "        self.memory = Replay_Memory(max_mem)\n",
    "        self.critic_loss = nn.MSELoss()\n",
    "        self.random_process = OrnsteinUhlenbeckProcess(size=nb_actions, theta=args.ou_theta, mu=args.ou_mu, sigma=args.ou_sigma)\n",
    "        \n",
    "        for target_param, param in zip(self.actor_target.parameters(),self.actor.parameters()):\n",
    "            target_param.data.copy_(param.data)\n",
    "        \n",
    "        for target_param, param in zip(self.critic_target.parameters(),self.critic.parameters()):\n",
    "            target_param.data.copy_(param.data)\n",
    "        \n",
    "        \n",
    "    def get_action(self,state):\n",
    "        probs = self.actor(t(state))\n",
    "        dist = torch.distributions.Categorical(probs=probs)\n",
    "        action = dist.sample()      \n",
    "        return action\n",
    "    \n",
    "    \n",
    "    def update(self):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Pendulum-v0\")\n",
    "env.reset()\n",
    "# plt.imshow(env.render('rgb_array'))\n",
    "\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 3 required positional arguments: 'state_size', 'action_size', and 'mem_cntr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-87760410758a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmax_mem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtau\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDDPGagent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_mem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtau\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-fefba5c04957>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, state_size, action_size, lr, max_mem, tau)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReplay_Memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_mem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_process\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrnsteinUhlenbeckProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mou_theta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mou_mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mou_sigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 3 required positional arguments: 'state_size', 'action_size', and 'mem_cntr'"
     ]
    }
   ],
   "source": [
    "num_episodes = 50\n",
    "lr = 0.0005\n",
    "max_mem = 50000\n",
    "tau = 0.01\n",
    "agent = DDPGagent(state_size,action_size,lr,max_mem,tau)\n",
    "batch_size = 64\n",
    "gamma = 0.99\n",
    "\n",
    "episode_rewards = []\n",
    "step = 0\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = agent.get_action(state)\n",
    "        next_state, reward, done, info = env.step(action) #.detach().data.numpy())\n",
    "\n",
    "        agent.memory.add_to_memory(state,action,reward,next_state,done)\n",
    "        \n",
    "        if agent.memory.get_memory_size() > batch_size:\n",
    "                agent.update(batch_size)\n",
    "                \n",
    "        total_reward += reward\n",
    "        state = next_state\n",
    "        step += 1\n",
    "\n",
    "#         if done: \n",
    "#             break\n",
    "    \n",
    "    episode_rewards.append(total_reward)\n",
    "    print('done')\n",
    "    if episode % 10 == 0:\n",
    "        \n",
    "        print('Episode {}'.format(episode))\n",
    "        print('Last Episode Reward: {}'.format(total_reward))\n",
    "        print('-'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmYHVWd//H3p5esnT1NCGQPSwiCAUJEQISwhWVU1FFQlFH8Aa4wgwugI4OKMgq4zIKCMDJuCKIDw6AjAoFBIRgwrGEJIWELSWclnbXT+f7+qLrN7U7fvrc7fbs7tz6v57lPV506Veecqur63qo6t0oRgZmZZVdVb1fAzMx6lwOBmVnGORCYmWWcA4GZWcY5EJiZZZwDgZlZxjkQWK+SNEBSSBrX23XpLEkPSTqzt+vRWZJ+IumL3bzM8yT9sTuXaT3HgcB2IKkx77Nd0qa88Q8XmXeOpEU9VVfrvIj4u4j4dm/Xw/qOmt6ugPU9EVGXG5a0BPhERPT6tz1JVQARsb2Hy62JiG09WWZfKt8qn88IrNMkDZT0b5KWSXpF0nck1UoaBfwWmJJ3BjFK0hGS5klaJ+k1Sd+VVNKXkPTyy9ckzQM2AntIGinpPyW9LullSZfmgkSatn86/In0stOUdPwzkm5KhwvWKe9y1SclvQA8maafIul5SWslXV2k3ldI+qWkWyWtl/SXXL3S6eMl3SZppaTFks5rM+8vJP1K0nrg9ALb4Htp+1+X9C+S+qfT5khaJOkySavT5f9t3rw3SfpKOry7pN+nbVol6Z68fAdI+r902uOSTsqbtpukOyW9IelBYGKb+r1F0j2S1khaKOk9HW5o61UOBNYVlwEHAgcAhwBHA1+MiFXAacDiiKhLP6uAJuAzwEjgHcDfAJ/oRHlnAh8FhgCvAz8H1gFTgFnAe4CPpHnvT+sDcBSwGHhn3vh96XApdTo1bd9BknYHbgYuBOqBBmBmkXq/D7gxLeM24DeSqiVVA3cCfwb2AOYAl0h6ZzvzDgNubWfZ3wXGkWyDfYF9gIvypk8C+gG7A+cAN0qa3M5yvgQ8C4wGxgL/BEkwBO4A/itt7xeAW/KWcS2wGhgDfBL4eG6BkoYCdwHXp8v9KHCDpL0KrSjrZRHhjz8FP8AS4Lg2aa8Cs/PG3w08kw7PARYVWeZFwC/T4QFAAOMK5H0IuCRvfCKwAajNS/sY8Lt0+NPAzenwYuD/AT9Jx18HpneiTofnTT8HmJs3Xg2sAM4ssLwr2uSvAVYBh5IEpufb5L8MuCZv3j90sP5qgK3AnnlpxwAL87bBZmBA3vTbgS+kwzcBX0mHvw3cAkxpU8bxwFJAeWm/TdfTAGA7MClv2tXAH9Phs4C72izvRuBLvb0/+9P+x/cIrFMkieRb5tK85KXAnh3MMx24CjgYGEhyIPtTJ4p9OW94IsmBqCGpCpCc2eZuUN8HfFXSBJKA8RvgYknT0nwLO1Gn/HL3yB+PiGZJr5Za74jYJum1dDnDgEmS1ublrQb+2N687dgDqAWeylsHAvLvIzRExOa88aXpfG1dDnwNuFdSE/DvEXF1mvelSI/iecvYk2T7q00dl5KcJUKyjY5q074aYE0HbbJe5EtD1inpgeF1Wl8TnkBylgDJN+m2rgMeBaZGxFCSA4/ayVew2Lzhl4FGYEREDE8/QyPi4HT6UyQH1fOA+yK5NNVIcnni/rwDWyl1yi93GTA+N5LekygY/FL5+atJDq6vpW14Jq/+wyNiSEScVqDstpaRHPSn5s0/LCJG5eUZnV7eyZmQlt26gRHrIuL8iJhIcjnqK5KOSPNOaJM9t51fT+s3vs20nJdJzmjy21cXERd00CbrRQ4E1hW/BC5NbwTvBnwZ+Fk6bTmwm6S6vPxDgHUR0ZjeMP1/XS04Il4kuVz0bUlDJFVJ2lvSken0ILlP8BnevB9wX5vxrtTpduBQSadKqiW5Zj6yyDyH5+X/IsmloUeBBwAkXZDemK6RdKCkgztaWN46aAJuAL4vabQS4yUdn5etFvhHSf0kzSa51LPDvQZJ75I0OT3TWwc0p5//A6rSOtakyz4BuCU90/hv4LL0pvWBQH634v8iua/yQSWdCPpJOkzSPqW0z3qeA4F1xVeBp0m+fS8guaSS65f+GMlBc2na22Qk8PfAJyQ1Av8G/Gonyz8DGA48Q3LD8lckNy1z7iM50N9fYJzO1ikilpH03vkeyY3iMcD8IvW8leQm6hqSb9vvi4jm9EB+MnA4ySWVBuAaoK7QgtpxAcm39vkkB/DfA/k3Y5eQnDW8ThI0PhYRi9tZzn7AXGA9yfq5MiIeSg/2pwLvJwlgVwMfjIgX0vnOJVkHy4EfAf+RW2BErAFOJLl3syyt5zdIgpP1QWp9CdDMuoOkK4DREdGZ3lHdVfYc4F8jwr10rCQ+IzAzyzgHAjOzjPOlITOzjPMZgZlZxu0SPygbPXp0TJo0qberYWa2S3nkkUdWRkR9sXy7RCCYNGkS8+cX66lnZmb5JC0tnsuXhszMMs+BwMws4xwIzMwyzoHAzCzjHAjMzDLOgcDMLOMcCMzMMq6iA0FEcOsjr7Bpa3NvV8XMrM+q6EDw5xdWceEtj3H5nU/3dlXMzPqsig4E6zcnr3Bd8caWXq6JmVnfVdGBwMzMiqvwQOBHbJuZFVPhgSAh9XYNzMz6rkwEAjMzK8yBwMws4xwIzMwyzoHAzCzjKjoQhDsNmZkVVdGBIEe425CZWSFlCwSSBkh6WNJjkp6SdFma/hNJL0pakH5mlKsOZmZWXDlfXr8FmB0RjZJqgQck/S6d9oWI+HUZyzYzsxKVLRBERACN6Wht+vFVezOzPqas9wgkVUtaAKwA7oqIeemkyyU9Lum7kvoXmPccSfMlzW9oaChnNc3MMq2sgSAimiNiBjAOmCXpLcDFwDTgUGAk8KUC814bETMjYmZ9fX3Xyu9atc3MMqVHeg1FxFpgLjAnIpZFYgvwH8CscpfvZw2ZmRVWzl5D9ZKGp8MDgeOAZySNTdMEvAd4slx1MDOz4srZa2gscKOkapKAc3NE3CHpHkn1gIAFwHllrIOZmRVRzl5DjwMHtZM+u1xlmplZ52Xil8VmZlZYRQcCP2vIzKy4ig4EOe41ZGZWWCYCgZmZFeZAYGaWcQ4EZmYZV9GBIPyQCTOzoio6EOT4xTRmZoVlIhCYmVlhDgRmZhnnQGBmlnEOBGZmGVfRgcCPmDAzK66iA0ELdxoyMysoG4HAzMwKciAwM8s4BwIzs4xzIDAzy7iKDgTuNGRmVlxFB4IcdxoyMyusogPBbX99tberYGbW51V0IHjkpTW9XQUzsz6vogOBmZkV50BgZpZxFR0I/KwhM7PiyhYIJA2Q9LCkxyQ9JemyNH2ypHmSnpf0K0n9ylWHvLqUuwgzs11WOc8ItgCzI+KtwAxgjqTDgH8GvhsRewNrgLPLWAczMyuibIEgEo3paG36CWA28Os0/UbgPeWqg5mZFVfWewSSqiUtAFYAdwEvAGsjYlua5RVgzwLzniNpvqT5DQ0N5aymmVmmlTUQRERzRMwAxgGzgP3ay1Zg3msjYmZEzKyvr+9S+b41YGZWXI/0GoqItcBc4DBguKSadNI44LXylVuuJZuZVY5y9hqqlzQ8HR4IHAcsBO4F3p9mOwu4rVx1aKlLuQswM9uF1RTP0mVjgRslVZMEnJsj4g5JTwM3SfoG8Ffg+jLWwczMiihbIIiIx4GD2klfTHK/wMzM+oCK/mWxmZkV50BgZpZxFR0Iwt2GzMyKquhAkOPfE5iZFVbRgcAPmzMzK66iA4GZmRXnQGBmlnEOBGZmGVfRgcC9hszMiqvoQJDjW8ZmZoVlIhCYmVlhDgRmZhnnQGBmlnEVHQj8gzIzs+IqOhC415CZWXEVHQhyfGZgZlZYJgKBmZkV5kBgZpZxDgRmZhnnQGBmlnEOBGZmGZeJQOA+Q2ZmhWUiEJiZWWEOBGZmGedAYGaWcWULBJLGS7pX0kJJT0k6P03/J0mvSlqQfk4uVx3MzKy4mjIuextwYUQ8KmkI8Iiku9Jp342IK8tYNgB+0pCZWXFlCwQRsQxYlg6vl7QQ2LNc5XXI3YbMzArqkXsEkiYBBwHz0qTPSHpc0g2SRhSY5xxJ8yXNb2ho6IlqmpllUtkDgaQ64Fbggoh4A7gGmArMIDljuKq9+SLi2oiYGREz6+vry11NM7PM6vDSkKSRHU2PiNVF5q8lCQI/j4jfpPMsz5t+HXBHybXtJF8RMjMrrtg9gkdI7rkKmACsSYeHAy8BkwvNqOQlANcDCyPi6rz0sen9A4DTgCe7XHszM9tpHQaCiJgMIOmHwO0RcWc6fhJwXJFlHwF8BHhC0oI07RLgDEkzSALMEuDcLte+CPcaMjMrrtReQ4dGxHm5kYj4naSvdzRDRDxA+1dn7uxE/bqFfJHIzKygUgPBSklfAX5G8kX7TGBV2WplZmY9ptReQ2cA9cBv0099mmZmZru4omcEkqqBiyPi/B6oj5mZ9bCiZwQR0Qwc0gN1MTOzXlDqPYK/SroduAXYkEvM/TbAzMx2XaUGgpEkN4dn56UFsEsEArnTkJlZQSUFgoj4WLkrYmZmvaOkQCBpAHA2sD8wIJceER8vU73MzKyHlNp99KfA7sCJwH3AOGB9uSplZmY9p9RAsFdE/COwISJuBE4BDihftczMrKeUGgia0r9rJb0FGAZMKkuNupMfNmRmVlSpvYauTV8g84/A7UBdOrxLcKchM7PCSu019ON08D5gSvmqY2ZmPa3UXkMvAA8B/wfcHxFPl7VW3cWnAmZmRZV6j2A68CNgFHClpMWSflu+apmZWU8pNRA0k9wwbga2A8uBFeWqlJmZ9ZxSbxa/ATwBXA1cFxG7xrsI3GvIzKyozryP4H7gU8BNki6TdGz5qtW9/KwhM7PCSu01dBtwm6RpwEnABcAXgYFlrJuZmfWAks4IJN2a9hz6PjAY+CgwopwVMzOznlHqPYIrgEfTl9SYmVkFKfUewVPAxZKuBZC0t6RTy1etbuJ7A2ZmRZUaCP4D2Aocno6/AnyjLDXqTu41ZGZWVKmBYGpEfJv04XMRsYld6Pu2dp2qmpn1uFIDwVZJA0m/Y0uaCmwpW63MzKzHFA0EkgT8EPg9MF7Sz4G7SbqPdjTfeEn3Sloo6SlJ56fpIyXdJen59K97H5mZ9aKigSAiAjgfeC/wd8AvgZkRMbfIrNuACyNiP+Aw4NOSpgMXAXdHxN4kAeWiLtfezMx2WqndRx8CpkTE/5S64IhYBixLh9dLWgjsCbwbODrNdiMwF/hSqcs1M7PuVWogOAY4V9JSYAPJjeKIiANLmVnSJOAgYB4wJg0SRMQySbsVmOcc4ByACRMmlFjN1txpyMysuFIDwUldLUBSHXArcEFEvKESH/wTEdcC1wLMnDlzp47pftaQmVlhpT5raGlXFi6pliQI/DwifpMmL5c0Nj0bGEsZH2ft47+ZWXGldh/ttLS30fXAwoi4Om/S7cBZ6fBZwG3lqoOZmRVX6qWhrjgC+AjwhKQFadolJM8tulnS2cBLwN+WsQ5mZlZE2QJBRDxA4aszPfIuA98sNjMrrmyXhvoS3yw2MyssE4HAzMwKcyAwM8s4BwIzs4xzIDAzyzgHAjOzjMtIIHC3ITOzQjISCMzMrBAHAjOzjHMgMDPLOAcCM7OMq+hAkLxl08zMOlLRgSDHzxoyMyusogNBqW9DMzPLsooOBGZmVpwDgZlZxjkQmJllXEUHAvcaMjMrrqIDQY5vGZuZFZaJQGBmZoU5EJiZZZwDgZlZxlV0IPAPyszMiqvoQOBeQ2ZmxVV0IMjxiYGZWWFlCwSSbpC0QtKTeWn/JOlVSQvSz8nlKt/MzEpTzjOCnwBz2kn/bkTMSD93lrF8MzMrQdkCQUTcD6wu1/LNzKx79MY9gs9Iejy9dDSiUCZJ50iaL2l+Q0NDT9bPzCxTejoQXANMBWYAy4CrCmWMiGsjYmZEzKyvr++p+pmZZU6PBoKIWB4RzRGxHbgOmNUT5cpPGzIzK6hHA4GksXmjpwFPFsprZmY9o6ZcC5b0S+BoYLSkV4BLgaMlzQACWAKcW67yzcysNGULBBFxRjvJ15erPDMz65qK/mXxhq3NAAR+1ISZWSEVHQhy1m5s6u0qmJn1WZkIBH4KqZlZYZkIBGZmVpgDgZlZxjkQmJllXCYCge8QmJkVlolAYGZmhWUiELjTkJlZYZkIBGZmVpgDgZlZxmUiEPjKkJlZYZkIBH7SkJlZYZkIBD4jMDMrLBOBwMzMCnMgMDPLuEwEAt8jMDMrLBOBwMzMCstEIAifEpiZFZSJQGBmZoWV7eX1fdm6jU1saW7m+eWNHDhuGEMG1LJ6w1YigudXNDJt9yEMH9SPRSsaqetfwwOLVnL8fmPYsq2Zxi3bmDhqMNVVIiJ4oaGRXAfVAbVVbNm2nabm7WxrDvYbO5T5S1YzbfehBEFTczCoXzXrNjXxxuYmBtRU07+2iiEDaqnrn2yKV9duYsSgWpat28z27cHeY4bQuGUbj7+yllmTRlJTXcWK9ZvpX13NsEG1HbZzzYatNEcwuq4/L63ayJhh/WlYv4XnVzQydEANh0wcCcCzr6+nX00V6zY1MWZof7YHNG3bTnWVknrWVjNyUD9WNm6hukpMqa+jccs2Fry0ln13H0JttRg+qB8AG7du49U1m9i4tZlJowczbGBty/rebcgAAF5atZHdhvZn7cYmBvevZvkbW9hrtzoANjc107B+C+NHDmLRikam1g9GEhu2bOPRl9YwdtgA9tptSKt2bmvezstrNjFh5CCWrtrA9ogd8gA8+MIqpo8dyrBBtTQ1b+e55esZMagfazZuZWXjVurr+jOwXzWTRw8GYMUbm+lfW82wgW+u50Ur1gPssPxnX1/P+s1NTK2vY8Tgfi3pr6/bzLwXV1Ff1599dx/Cxq3NvLR6IzVVYtbkkS1vz3tx5QbGjxhITXUVf1q0kt2HDWB0XX8a1m9man0dDeu38PKaTQwbWMPQgbW8vHojh0wcyaIVjUwcNYhfzHuJD8wcz8B+1S3b/sVVG9h/j6G8vHojVRLbtgdVgv411dQP6c+A2uqW9T2wXzXVEms2bm3Zv3NeXr2xJf+iFY1MGT2Y5gheXbMJgD1HDKS2uoqNW7exZmMTm5uamTxqMFu2beeJV9cxsLaaA8YNY+u27Sxbt4mJowa37CtrNjZRWy0efnE1x+y7G4P717BlWzN/eXENh04eQf+aahY3NNKvpooFL6/l+Olj6F/zZhtfXbuJRSsaeddb96CqSq3WY85LqzYysq4fqxu3sm379pb2vbhyA1u2NTNt96Gs39zEhi3J//e6TVvZui14+9RRACxbt6nlf3RV4xbue66BPYcPZMmqDbx7xp4MqK1my7Zmlq/bwoRRg1rtF6+t3US/mipWNm5h3cYmDpowgn41rb9/L1qxnqn1dbzQsIHaajF22EBeWr2h3f2sXDIRCNpeGTr08j+ytXl7y/iSK07h4K/f1SrPrZ88nPdd8+d2l/fZ2Xtx4Qn7csv8V/jirY8XLHfa7kN45vX1rdLesudQnnz1jVZpU+sHc/eFRwNwxBX3MGJQLWvS9yz/92eO5L3X/Imm5uDcd07h4pP2Y9bld1NbLZ6//OSOms1BaZsWfm0OR33nXt711j24/bHXWqZf99GZjB02gFP/5YEOl9PWvZ8/mmOunNsyXiVY/K1TADjjunk89vJaAOr61/DkZScy8/K7aGoOllxxCpubmjnqO/dyyoFj+Z/Hl7Us49fnvZ2Zk0byDzcv4M4nXm9Z/5ecPI1zjprK/pf+b0veX3zibRy+1+iW8avueo5r5r7Au2fswW0Lkvbd+PFZvHOf+pY88xav4ozrHgKS7f21/36anz60tN32PX/5SdRWVzHrm3czoLaKZ75+EgBbtjVz3NX3A/DsN+a0HJCWrNzAid+7v2X+JVec0jJ82LfuLrgeL3vX/px1+CReXr2RY66cyzlHTeGQiSM496ePtMr3zdMO4JLfPrHD/Ff+7Vv5/C2PtYxfevtTLWXntv3oun6sbNy6w7wnTB/DtR+dyQU3LeD3T73eatrnjt2bfzh+HwCamrfzjm/fy4n7j+Fzx+7NKT94gC/Nmcbr6zZx44PJ+vvw2yZw+WkHcOaP5/HoS8m2v/D4fXhw8Sr+/MIqABZ/82Qu+e0T/PqRV3js0hMYNrCWD103jwXpvgKwz5g6/vD37+Szv/grf3h6OcftN4avnjqd2Vfd15Ln5AN2598/fEirNgIsWbWBDx46nmOunMvHj5jMV/9mOpAEm6O+c2+r9n3q6Kl8cc60ln14yRWncMoPHuCl1Rtb5cvtk2//1j1MHj2Yez9/NId844+t8nzp1idYcsUpXHjzY9zx+DKe+focBtRWt0w//Ip7WuU/Y9Z4vvXeA1vG73uugbNueLjdYwXAD888hDlv2X2H9O5W0ZeGxo0Y2G56fhAoZOmqDQWn/WXJagCeeHVdh8tob8O2DQIALzS0LisXBABeXbuRpuYklD20eHVLei6tFFu2NQMw99kVrdKfW76el9vs/KVY8cbmVuPb86ryWN4/duOWbUDrujal637uM63rsnhlsg7ufaYBSL4hAzy6dC1tLWpobDX+8IvJeskPLM8vb73uc8vP+dMLK3dYbk5zXoM2N21vNz1/eMX6LQWX1ZHculq1ITlQz1u8iufa2Wcef2XHdQDw0OJVRctoLwgAzH02Wc9zn1uxw7SHX3xzubl23vtMA6+kZwCPLF3Dg3llP5ge7HNBAGD+0jUtQQCSL2P3P5eUuWlrsj/mBwGA55Yn2/UPTy8H4I8Ll9PQ2Hrd/nHhjvUFmL9kDavStuavl/ztlzPvxdU7pLUNAgBLV72Z9uLKwscDeHN9NhU5tvxpUettlttP2ztWJOk7Hi/KoaIDQb/09DC6+W6x0ktB0SMdU/N+F93FdrxZ39YiotVBvFQ70+rcpZAdltEmQS3JO5bWdjXkrmJs72D97DCtg0YUWo66+TfquXLUMg5VVTuWUahZ3bFbV7XzjPb85eYmB5HX+ii6LjqqWmceC992dRSaNX+b5Zfdzuos+XjQmXq2bMsiM3X2kfg91dGlogMBLTtxeXT3RmpvB83fcbpanHJbue2xMDo+eBayM+1uOcDvcFxundByAGqnrLbrqaqd4NJ2vrYBr6MmNBeIjvl17EoA3XF5iVYH2/YOXAVquzNfRHLzthcIWuXLK6JlPUfxA1rbbRTRtdoWq19O8/bI22feLKm9A3Op267Uslsvu3OtLBY4uvtLbCFlCwSSbpC0QtKTeWkjJd0l6fn074hylb+zeuNlNsV20K4ctCH/G2ebf066Fly640yobV1ybc+t99zf9tZJ27T8A1Sh5bd3YCpYtwJn99s7WH5X5BbRcsYW7Z91dEfQKaS93by9gJp/8C+l7Z04AetQqQfjQuuu3cBahjOClvVU/Kpzp5Rz2+cr5xnBT4A5bdIuAu6OiL2Bu9PxPqk3fnvQ3jfRrnwraatQUyK6+I1jJ9ZNtPmbX5f8v8q7OFSs+Kp29uK2ebZ34j9qW4FIkL+uOrO8QnY4IyjwTbvgJtqpM7NcxG2vvPzLLNFSVH7din6TbVO5ZF9LhgudcbVbzzbFFJqzuRP7cTn+tXPBsTu+IOTrmcvPoHKeekiaBNwREW9Jx58Fjo6IZZLGAnMjYt9iy5k5c2bMnz+/0+Ufe9XcHW7EWuUYObgfqze0fzO0p+y1Wx2LVjQWz2jWRS9+6+SigbcQSY9ExMxi+Xr6HsGYiFgGkP7drVBGSedImi9pfkNDQ5cKO/edU7tWS9sl9HYQABwErOz+a8GrZS+jz94sjohrI2JmRMysr68vPkM7PjBzfDfXysysZ60q0AW4O/V0IFieXhIi/dt+p2AzMwO6/75De3o6ENwOnJUOnwXc1sPlm5ntUjrz49GuKmf30V8CDwL7SnpF0tnAFcDxkp4Hjk/HzcysgM70suqqsj1rKCLOKDDp2HKVaWZWabaV8EicndVnbxabmRk09cAZgQOBmVkfduik8j+AoeIDQf4jgSvVjPHDe63sZ77e9sfj1l0OmzKy1fjczx/drcsfUFvx//475cnLTuztKvAvZxzE7Gljyl6O94QK0N4TFntKdW8WXuHa9hqsrenef9fq3nig1i6kL+zaPfWkGweCCtDVn593h+54FpK1r+1BoLa6e9e1t13H+sL62eWfPmo9pzd3177wralStT0I9K+uLpCza/rAca5P6wuBoCd+TAYOBBWhN/fX3jwbqXRtjwFt33W7s3xZr2N9YfX4xTRWsvx3pFrlaLtda7r50tDg/pl4ZXmX9YUzgp4K1pkIBJ87dm8ARg3ux6xJSU+M758+gyPzXoA+fFBtq3lyL+/+3Oy9dljeKQeM5TefOpxPH7Pj003z35P8jr1Hc8nJ01rKzxncr/U/+DH71re8VvMTR05uSZ88enDLcG6HOHDcMGZPe/OhrUfvW89VH3grn5291w5t6MiYof35/ukzdqjXtN2H8MMzD+b6s2a2rINL/2Y6+44Z0pJv7LABQPIibkheog7wz+87oGB5x6Z1PuvtE5lSP5ghA2q4+gNv5ci9RvP902cwbfdk+RNHDeKD6cMC90jLeeu4YQAt2+6yd+0PwNffvT+XvWv/Vtsx5+y89dhWbjmQbK+6vANi/v/+6Lp+BZfR1ldPnc71Z735tN+PHDaRD71tQsv4xFGDWobv+OyRTB87tGX8vPQpud9+34F8YOY4AH7zqcO5Ot2uADMnjqC2uqplvjFD+7cqP3/7ABw0YTgfftsErnjvm9skvw4/PPNgfnb221rNU10ljttvN/YcnuzD+4ypazX9TxfN5vx0X5Zo2f8vP+0trfJNSsvJP4iduP+YHbbT2UdO5qAJw6muEr87/x2MGpys79MO2rMlz+dP2Idzj5rC3x0+qSXt40dMZmr94B3OhL952pttHdgmiI7I+99o713m//qhg1qGzz1qCl8+eT+qqsSvz3s7sOPZQV2RINresSHf/nsM5T0z9ugwz9hhAzj5gLEd5ukuZX0fQXfp6vtPW9TlAAAGnUlEQVQIzMyyrK++j8DMzPoYBwIzs4xzIDAzyzgHAjOzjHMgMDPLOAcCM7OMcyAwM8s4BwIzs4zbJX5QJqkBWNrF2UcDK7uxOrsCtzkb3OZs2Jk2T4yI+mKZdolAsDMkzS/ll3WVxG3OBrc5G3qizb40ZGaWcQ4EZmYZl4VAcG1vV6AXuM3Z4DZnQ9nbXPH3CMzMrGNZOCMwM7MOOBCYmWVcRQcCSXMkPStpkaSLers+O0PSDZJWSHoyL22kpLskPZ/+HZGmS9IP0nY/LungvHnOSvM/L+ms3mhLKSSNl3SvpIWSnpJ0fppeyW0eIOlhSY+lbb4sTZ8saV5a/19J6pem90/HF6XTJ+Ut6+I0/VlJJ/ZOi0onqVrSXyXdkY5XdJslLZH0hKQFkuanab23b0dERX6AauAFYArQD3gMmN7b9dqJ9hwFHAw8mZf2beCidPgi4J/T4ZOB3wECDgPmpekjgcXp3xHp8IjebluB9o4FDk6HhwDPAdMrvM0C6tLhWmBe2pabgdPT9B8Cn0yHPwX8MB0+HfhVOjw93d/7A5PT/4Pq3m5fkbb/A/AL4I50vKLbDCwBRrdJ67V9u5LPCGYBiyJicURsBW4C3t3LdeqyiLgfWN0m+d3AjenwjcB78tL/MxIPAcMljQVOBO6KiNURsQa4C5hT/tp3XkQsi4hH0+H1wEJgTyq7zRERjelobfoJYDbw6zS9bZtz6+LXwLGSlKbfFBFbIuJFYBHJ/0OfJGkccArw43RcVHibC+i1fbuSA8GewMt546+kaZVkTEQsg+TACeTeal+o7bvkOklP/w8i+YZc0W1OL5EsAFaQ/GO/AKyNiG1plvz6t7Qtnb4OGMUu1mbge8AXge3p+Cgqv80B/EHSI5LOSdN6bd+u6cpMuwi1k5aVvrKF2r7LrRNJdcCtwAUR8Uby5a/9rO2k7XJtjohmYIak4cBvgf3ay5b+3eXbLOlUYEVEPCLp6FxyO1krps2pIyLiNUm7AXdJeqaDvGVvcyWfEbwCjM8bHwe81kt1KZfl6Ski6d8VaXqhtu9S60RSLUkQ+HlE/CZNrug250TEWmAuyTXh4ZJyX9ry69/StnT6MJLLh7tSm48A3iVpCcnl29kkZwiV3GYi4rX07wqSgD+LXty3KzkQ/AXYO+190I/kxtLtvVyn7nY7kOspcBZwW176R9PeBocB69JTzf8FTpA0Iu2RcEKa1uek132vBxZGxNV5kyq5zfXpmQCSBgLHkdwbuRd4f5qtbZtz6+L9wD2R3EW8HTg97WEzGdgbeLhnWtE5EXFxRIyLiEkk/6P3RMSHqeA2SxosaUhumGSffJLe3Ld7++55OT8kd9ufI7nO+uXers9OtuWXwDKgieSbwNkk10bvBp5P/45M8wr4t7TdTwAz85bzcZIbaYuAj/V2uzpo75Ekp7mPAwvSz8kV3uYDgb+mbX4S+GqaPoXkoLYIuAXon6YPSMcXpdOn5C3ry+m6eBY4qbfbVmL7j+bNXkMV2+a0bY+ln6dyx6be3Lf9iAkzs4yr5EtDZmZWAgcCM7OMcyAwM8s4BwIzs4xzIDAzyzgHArMiJH1N0nHdsJzG4rnMep67j5r1EEmNEVHX2/Uwa8tnBJZJks5U8uz/BZJ+lD7srVHSVZIelXS3pPo0708kvT8dvkLS0+lz4a9M0yam+R9P/05I0ydLelDSXyR9vU35X0jTH1f63gGz3uJAYJkjaT/ggyQP/poBNAMfBgYDj0bEwcB9wKVt5hsJnAbsHxEHAt9IJ/0ryWOCDwR+DvwgTf8+cE1EHAq8nrecE0gegTALmAEcIumocrTVrBQOBJZFxwKHAH9JH/l8LMnP/rcDv0rz/IzkMRf53gA2Az+W9F5gY5r+dpKXqgD8NG++I0geDZJLzzkh/fwVeBSYRhIYzHpFJT+G2qwQATdGxMWtEqV/bJOv1Q20iNgmaRZJ4Dgd+AzJ0zLbigLD+eV/KyJ+1NmKm5WDzwgsi+4G3p8+Cz73rtiJJP8PuSdefgh4IH+m9N0IwyLiTuACkss6AH8mCQyQXGLKzfenNuk5/wt8PF0ekvbM1cWsN/iMwDInIp6W9BWSN0RVkTzR9dPABmB/SY+QvPnqg21mHQLcJmkAybf6v0/TPwfcIOkLQAPwsTT9fOAXks4nea9Crvw/pPcpHkxftNMInMmbz58361HuPmqWcvdOyypfGjIzyzifEZiZZZzPCMzMMs6BwMws4xwIzMwyzoHAzCzjHAjMzDLu/wOuwdD7grF3QgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(episode_rewards)\n",
    "plt.title(\"Total reward per episode\")\n",
    "plt.ylabel(\"reward\")\n",
    "plt.xlabel(\"episode\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'episode_rewards' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-a95861a174e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DDPG_LunarLander'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepisode_rewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'episode_rewards' is not defined"
     ]
    }
   ],
   "source": [
    "np.save('DDPG_LunarLander',episode_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
